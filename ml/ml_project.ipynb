{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.linalg as la\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import umap\n",
    "import pickle\n",
    "\n",
    "from sklearn import linear_model, model_selection, metrics\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as GDA\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import GridSearchCV,train_test_split,cross_val_score\n",
    "from sklearn.metrics import roc_auc_score as RAS\n",
    "from sklearn.metrics import roc_curve as ROC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`jupyter nbconvert --to latex \"Race and Incarceration in America.ipynb\" --TagRemovePreprocessor.remove_input_tags='{\"hide_input\"}'; pdflatex \"Race and Incarceration in America\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Last semester I took a look a data set containing the information of more than 7.5 million individuals that have been processed by the criminal justice system. I found that racial minorities were more likely to receive extreme sentences, agreeing with existing research around bias in the criminal justice system. In this project I will be exploring the data from a machine learning perspective. My goal is to determine if this data can be classified in such a way that is predictive of race."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Possible questions\n",
    "can we use ml techniques to correctly classify this data?\n",
    "which ones fail and why?\n",
    "can we create a predictive model for sentence lengths?\n",
    "should sentencing be offloaded to a ml algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TSNE is having mized results while UMAP doesn't seem to capture any good groupings. Maybe I should go straight to kmeans or kdtrees.\n",
    "I should block by crime and examine a few \"big\" crimes the try several different perplexities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize = 100000\n",
    "rdf = pd.read_csv('regression_df.csv', chunksize=chunksize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['RACE','GENDER','AGE','OFFENSE','FACILITY','DETAINER','SENTENCE DAYS']\n",
    "df = pd.read_csv('individuals.csv',usecols=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = df.sample(20000)\n",
    "samp.RACE = pd.factorize(samp['RACE'])[0] + 1\n",
    "samp.GENDER = pd.factorize(samp['GENDER'])[0] + 1\n",
    "samp.OFFENSE = pd.factorize(samp['OFFENSE'])[0] + 1\n",
    "samp.DETAINER = pd.factorize(samp['DETAINER'])[0] + 1\n",
    "samp.FACILITY = pd.factorize(samp['FACILITY'])[0] + 1\n",
    "samp_y = samp.RACE\n",
    "samp_X = samp[['GENDER','AGE','OFFENSE','FACILITY','DETAINER','SENTENCE DAYS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ethan/.local/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning:\n",
      "\n",
      "The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.71405"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': np.arange(100,400,20),\n",
    "    'max_depth': np.arange(10,100,10),\n",
    "    'max_features': np.arange(1,6)\n",
    "}\n",
    "def oob(clf, X, y):\n",
    "    return clf.oob_score_\n",
    "\n",
    "clf = RandomForestClassifier(oob_score=True)\n",
    "clf = GridSearchCV(clf, param_grid, scoring=oob, cv=5)\n",
    "clf = clf.fit(samp_X, samp_y)\n",
    "clf = clf.best_estimator_\n",
    "clf = clf.fit(samp_X, samp_y)\n",
    "print(clf.oob_score_)\n",
    "\n",
    "with open('RandonForestClf.pickle', \"wb+\") as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('RandonForestClf.pickle', \"wb+\") as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.71405\n",
      "[0.01082286 0.26735086 0.20718718 0.18534671 0.03167696 0.29761543]\n"
     ]
    }
   ],
   "source": [
    "with open('RandonForestClf.pickle',\"rb\") as f:\n",
    "    clf = pickle.load(f)\n",
    "print(clf.oob_score_)\n",
    "print(clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = df.sample(200000)\n",
    "samp.RACE = pd.factorize(samp['RACE'])[0] + 1\n",
    "samp.GENDER = pd.factorize(samp['GENDER'])[0] + 1\n",
    "samp.OFFENSE = pd.factorize(samp['OFFENSE'])[0] + 1\n",
    "samp.DETAINER = pd.factorize(samp['DETAINER'])[0] + 1\n",
    "samp.FACILITY = pd.factorize(samp['FACILITY'])[0] + 1\n",
    "samp_y = samp.RACE\n",
    "samp_X = samp[['GENDER','AGE','OFFENSE','FACILITY','DETAINER','SENTENCE DAYS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.340885"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(samp_X, samp_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
