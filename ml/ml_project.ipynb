{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ethan/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n",
      "/home/ethan/anaconda3/lib/python3.7/site-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  defaults = yaml.load(f)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.linalg as la\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import umap\n",
    "import pickle\n",
    "import time\n",
    "import xgboost\n",
    "\n",
    "from sklearn import linear_model, model_selection, metrics\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as GDA\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import GridSearchCV,train_test_split,cross_val_score\n",
    "from sklearn.metrics import roc_auc_score as RAS\n",
    "from sklearn.metrics import roc_curve as ROC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`jupyter nbconvert --to latex \"Race and Incarceration in America.ipynb\" --TagRemovePreprocessor.remove_input_tags='{\"hide_input\"}'; pdflatex \"Race and Incarceration in America\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Last semester I took a look a data set containing the information of more than 7.5 million individuals that have been processed by the criminal justice system. I found that racial minorities were more likely to receive extreme sentences, agreeing with existing research around bias in the criminal justice system. In this project I will be exploring the data from a machine learning perspective. My goal is to determine if this data can be classified in such a way that is predictive of race. The idea is that perhaps racial bias can be detected in various systems by seeing how effective different machine learning techniques are at classifying inmate data by race."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "## Source and Credibility\n",
    "The data that I will be using in this analysis is from one source. It is a [database](https://catalog.data.gov/dataset/sentenced-inmates-in-correctional-facilities) hosted on [Data.gov](https://www.data.gov) and maintained by the State of Connecticut Department of Corrections. This source is highly credible because it is a primary source for the data. This organization is an official government agency which collects, maintains, and reports on this data.\n",
    "\n",
    "## Gathering and Cleaning\n",
    "All the data which I am using in this report are freely available to the public. Collection and cleaning was relatively simple as the source data was well maintained. The file that I obtained from the Connecticut Department of Corrections is a very well maintained database. The largest issue I had with this file was mild inconsistency with the way in which certain data was encoded (ex. race was encoded as both `WHITE` and `WHITE\\t`). This was the data that I spent the most time working to engineer as it is a data set that I intend to use for different regression-related analyses. The files are\n",
    "```\n",
    "individuals.csv\n",
    "regression_df.csv.\n",
    "\n",
    "```\n",
    "## About the Data\n",
    "This data set contains individual information for 7.77 million people that have been processed by the justice system and recorded by the Connecticut Department of Corrections. Each individual is recorded along with their age, gender, race, offense, and sentence length, among other things [6].\n",
    "\n",
    "I also created one-hot encoded versions of this data set in order to run regressions on the data. Because of the size of the data, the regression data sets are only random subsets of the larger data set.\n",
    "\n",
    "Because there is so much to consider in what is found in the data set, I chose not to engineer more features as to avoid unneeded complexity.\n",
    "\n",
    "i ought to disclose the sample sizes among different races that are found in the Connecticut Department of Justice data. The sample size for American Indians and Asians is much smaller than that of Whites, Hispanics, and Blacks, hence we may see some irregular outcomes in the analysis related to these racial groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['RACE','GENDER','AGE','OFFENSE','FACILITY','DETAINER','SENTENCE DAYS']\n",
    "features = ['GENDER','AGE','OFFENSE','FACILITY','DETAINER','SENTENCE DAYS']\n",
    "df = pd.read_csv('individuals.csv',usecols=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size for Blacks: 3287596\n",
      "Sample size for Whites: 2393949\n",
      "Sample size for Hispanic: 2039297\n",
      "Sample size for American Indian: 21133\n",
      "Sample size for Asian: 35660\n"
     ]
    }
   ],
   "source": [
    "races = {'BLACK':'Blacks','WHITE':'Whites',\n",
    "         'HISPANIC':'Hispanic','AMER IND':'American Indian',\n",
    "         'ASIAN':'Asian'\n",
    "        }\n",
    "for rac in races.keys():\n",
    "    mask = df.RACE == rac\n",
    "    print(f'Sample size for {races[rac]}: {len(df[mask])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Possible questions\n",
    "can we use ml techniques to correctly classify this data?\n",
    "which ones fail and why?\n",
    "can we create a predictive model for sentence lengths?\n",
    "should sentencing be offloaded to a ml algorithm?\n",
    "what does it mean to have an effective classfifier for this data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TSNE is having mized results while UMAP doesn't seem to capture any good groupings. Maybe I should go straight to kmeans or kdtrees.\n",
    "I should block by crime and examine a few \"big\" crimes the try several different perplexities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunksize = 100000\n",
    "# rdf = pd.read_csv('regression_df.csv', chunksize=chunksize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['RACE','GENDER','AGE','OFFENSE','FACILITY','DETAINER','SENTENCE DAYS']\n",
    "features = ['GENDER','AGE','OFFENSE','FACILITY','DETAINER','SENTENCE DAYS']\n",
    "df = pd.read_csv('individuals.csv',usecols=cols) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Techniques\n",
    "\n",
    "## Random Forest Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = df.sample(20000)\n",
    "samp.RACE = pd.factorize(samp['RACE'])[0] + 1\n",
    "samp.GENDER = pd.factorize(samp['GENDER'])[0] + 1\n",
    "samp.OFFENSE = pd.factorize(samp['OFFENSE'])[0] + 1\n",
    "samp.DETAINER = pd.factorize(samp['DETAINER'])[0] + 1\n",
    "samp.FACILITY = pd.factorize(samp['FACILITY'])[0] + 1\n",
    "samp_y = samp.RACE\n",
    "samp_X = samp[['GENDER','AGE','OFFENSE','FACILITY','DETAINER','SENTENCE DAYS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to train is 223.73655876318614 minutes\n",
      "oob score is 0.70645\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': np.arange(100,400,20),\n",
    "    'max_depth': np.arange(10,100,10),\n",
    "    'max_features': np.arange(1,6)\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(oob_score=True)\n",
    "\n",
    "s = time.time()\n",
    "clf = GridSearchCV(clf, param_grid, scoring=None, cv=5)\n",
    "clf = clf.fit(samp_X, samp_y)\n",
    "e = time.time()\n",
    "print(f'time to train is {(e-s)/60} minutes')\n",
    "\n",
    "clf = clf.best_estimator_\n",
    "clf = clf.fit(samp_X, samp_y)\n",
    "print(f'oob score is {clf.oob_score_}')\n",
    "\n",
    "with open('RandomForestClf.pickle', \"wb+\") as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.70645\n",
      "[0.01022266 0.26942225 0.2124008  0.17300606 0.0338177  0.30113052]\n"
     ]
    }
   ],
   "source": [
    "with open('RandomForestClf.pickle',\"rb\") as f:\n",
    "    clf = pickle.load(f)\n",
    "print(clf.oob_score_)\n",
    "print(clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we can see that the most important features are sentence length, age, and offense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.291925"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samp = df.sample(200000)\n",
    "samp.RACE = pd.factorize(samp['RACE'])[0] + 1\n",
    "samp.GENDER = pd.factorize(samp['GENDER'])[0] + 1\n",
    "samp.OFFENSE = pd.factorize(samp['OFFENSE'])[0] + 1\n",
    "samp.DETAINER = pd.factorize(samp['DETAINER'])[0] + 1\n",
    "samp.FACILITY = pd.factorize(samp['FACILITY'])[0] + 1\n",
    "samp_y = samp.RACE\n",
    "samp_X = samp[['GENDER','AGE','OFFENSE','FACILITY','DETAINER','SENTENCE DAYS']]\n",
    "clf.score(samp_X, samp_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent Boosted Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = df.sample(10000)\n",
    "samp.RACE = pd.factorize(samp['RACE'])[0] + 1\n",
    "samp.GENDER = pd.factorize(samp['GENDER'])[0] + 1\n",
    "samp.OFFENSE = pd.factorize(samp['OFFENSE'])[0] + 1\n",
    "samp.DETAINER = pd.factorize(samp['DETAINER'])[0] + 1\n",
    "samp.FACILITY = pd.factorize(samp['FACILITY'])[0] + 1\n",
    "samp_y = samp.RACE\n",
    "samp_X = samp[['GENDER','AGE','OFFENSE','FACILITY','DETAINER','SENTENCE DAYS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'learning_rate': np.linspace(.01,1,10),\n",
    "    'subsample': np.linspace(.05,1,10),\n",
    "    'max_depth': np.arange(1,5)\n",
    "}\n",
    "\n",
    "clf = GradientBoostingClassifier(n_estimators=5000)\n",
    "\n",
    "s = time.time()\n",
    "# clf = GridSearchCV(clf, param_grid, cv=5)\n",
    "clf = clf.fit(samp_X, samp_y)\n",
    "e = time.time()\n",
    "\n",
    "# clf = clf.best_estimator_\n",
    "# clf = clf.fit(samp_X, samp_y)\n",
    "\n",
    "print(f'time is {(e-s)/60}')\n",
    "\n",
    "with open('GradientBoostedClf1.pickle', \"wb+\") as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = df.sample(200000)\n",
    "samp.RACE = pd.factorize(samp['RACE'])[0] + 1\n",
    "samp.GENDER = pd.factorize(samp['GENDER'])[0] + 1\n",
    "samp.OFFENSE = pd.factorize(samp['OFFENSE'])[0] + 1\n",
    "samp.DETAINER = pd.factorize(samp['DETAINER'])[0] + 1\n",
    "samp.FACILITY = pd.factorize(samp['FACILITY'])[0] + 1\n",
    "samp_y = samp.RACE\n",
    "samp_X = samp[['GENDER','AGE','OFFENSE','FACILITY','DETAINER','SENTENCE DAYS']]\n",
    "clf.score(samp_X, samp_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('GradientBoostedClf.pickle', \"rb\") as f:\n",
    "    clf = pickle.load(f)\n",
    "#     print(f'oob improvement {clf.oob_improvement_}')\n",
    "    print(f'{zip(clf.feature_importances_,features)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'friedman_mse',\n",
       " 'init': None,\n",
       " 'learning_rate': 0.34,\n",
       " 'loss': 'deviance',\n",
       " 'max_depth': 4,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 600,\n",
       " 'n_iter_no_change': None,\n",
       " 'presort': 'auto',\n",
       " 'random_state': None,\n",
       " 'subsample': 1.0,\n",
       " 'tol': 0.0001,\n",
       " 'validation_fraction': 0.1,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = df.sample(10000)\n",
    "samp.RACE = pd.factorize(samp['RACE'])[0] + 1\n",
    "samp.GENDER = pd.factorize(samp['GENDER'])[0] + 1\n",
    "samp.OFFENSE = pd.factorize(samp['OFFENSE'])[0] + 1\n",
    "samp.DETAINER = pd.factorize(samp['DETAINER'])[0] + 1\n",
    "samp.FACILITY = pd.factorize(samp['FACILITY'])[0] + 1\n",
    "samp_y = samp.RACE\n",
    "samp_X = samp[['GENDER','AGE','OFFENSE','FACILITY','DETAINER','SENTENCE DAYS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time was 1.7242353409528732 hours\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'learning_rate':np.linspace(.01,1,5),\n",
    "    'reg_alpha':np.linspace(.01,1,5),\n",
    "    'reg_lambda':np.linspace(.01,1,5),\n",
    "    'gamma':np.linspace(.01,1,5)\n",
    "}\n",
    "\n",
    "clf = xgboost.XGBClassifier(verbose=2)\n",
    "s = time.time()\n",
    "clf = GridSearchCV(clf, param_grid,cv=5)\n",
    "clf = clf.fit(samp_X, samp_y)\n",
    "\n",
    "with open('XBG_fitted_grid.pickle', 'wb+') as f:\n",
    "    pickle.dump(clf, f)\n",
    "\n",
    "clf = clf.best_estimator_\n",
    "clf = clf.fit(samp_X, samp_y)\n",
    "e = time.time()\n",
    "\n",
    "print(f'time was {(e-s)/(60*60)} hours')\n",
    "\n",
    "with open('XGBoostClf.pickle', 'wb+') as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4376"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samp = df.sample(200000)\n",
    "samp.RACE = pd.factorize(samp['RACE'])[0] + 1\n",
    "samp.GENDER = pd.factorize(samp['GENDER'])[0] + 1\n",
    "samp.OFFENSE = pd.factorize(samp['OFFENSE'])[0] + 1\n",
    "samp.DETAINER = pd.factorize(samp['DETAINER'])[0] + 1\n",
    "samp.FACILITY = pd.factorize(samp['FACILITY'])[0] + 1\n",
    "samp_y = samp.RACE\n",
    "samp_X = samp[['GENDER','AGE','OFFENSE','FACILITY','DETAINER','SENTENCE DAYS']]\n",
    "clf.score(samp_X,samp_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KD Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
