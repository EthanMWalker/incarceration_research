{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ethan/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n",
      "/home/ethan/anaconda3/lib/python3.7/site-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  defaults = yaml.load(f)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.linalg as la\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import umap\n",
    "import pickle\n",
    "import time\n",
    "import xgboost\n",
    "\n",
    "from sklearn import linear_model, model_selection, metrics\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as GDA\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import GridSearchCV,train_test_split,cross_val_score\n",
    "from sklearn.metrics import roc_auc_score as RAS\n",
    "from sklearn.metrics import roc_curve as ROC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "source": [
    "`jupyter nbconvert --to latex \"Race and Incarceration in America.ipynb\" --TagRemovePreprocessor.remove_input_tags='{\"hide_input\"}'; pdflatex \"Race and Incarceration in America\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "Machine Learning is becomeing a more prevelant tool in the world of criminal justice. Often it is used to predict who will commit a crime or where crimes may occur. Seldom is it used to regulate the criminal justice system, however. In this project I examine prison inmate data and determine what machine learning techniques are effective at detecting the racial bias that has been shown to exist in this data. In this report I find ---------\n",
    "\n",
    "# Problem Statement and Motivation\n",
    "Last semester I took a look a data set containing the information of more than 7.5 million individuals that have been processed by the criminal justice system. I found that racial minorities were more likely to receive extreme sentences, agreeing with existing research around bias in the criminal justice system. In this project I will be exploring the data from a machine learning perspective. My goal is to determine if this data can be classified in such a way that is predictive of race. The idea is that perhaps racial bias can be detected in various systems by seeing how effective different machine learning techniques are at classifying an inmate's by race given their data.\n",
    "\n",
    "This is an unconventional way to approach criminal justice data with machine learning. Often we see machine learning being used to attempt to determine who might be a criminal or where crimal activity may occur using social media data and other public information, which may include data the government owns, but which is not available to te public. These approaches often ignore or discount the ways that these techniques may disproportionately affect people of color and the poor. Many organizations have made official statements reguarding the use of machine learning in this way, often called predicitive policing. The ACLU for example released a statement listing civil rights related concerns about predicitive policing which was signed by several civil rights origanizations includeing the NAACP [[1]](https://www.aclu.org/other/statement-concern-about-predictive-policing-aclu-and-16-civil-rights-privacy-racial-justice).\n",
    "\n",
    "My objective is to go against the predictive policing paradigm and use machine learning to benefit these negatively affected classes of people by using machine learning as a diagnostic tool. If it can be shown that certain machine learning techniques are effective at classifying inmates by race given incarceration related information, then we can inform policies that will attempt to correct for these systemic racial biases. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "## Source and Credibility\n",
    "The data that I will be using in this analysis is from one source. It is a [database](https://catalog.data.gov/dataset/sentenced-inmates-in-correctional-facilities) hosted on [Data.gov](https://www.data.gov) and maintained by the State of Connecticut Department of Corrections. This source is highly credible because it is a primary source for the data. This organization is an official government agency which collects, maintains, and reports on this data.\n",
    "\n",
    "## Gathering and Cleaning\n",
    "All the data which I am using in this report are freely available to the public. Collection and cleaning was relatively simple as the source data was well maintained. The file that I obtained from the Connecticut Department of Corrections is a very well maintained database. The largest issue I had with this file was mild inconsistency with the way in which certain data was encoded (ex. race was encoded as both `WHITE` and `WHITE\\t`). The file is\n",
    "```\n",
    "individuals.csv.\n",
    "\n",
    "```\n",
    "## About the Data\n",
    "This data set contains individual information for 7.77 million people that have been processed by the justice system and recorded by the Connecticut Department of Corrections. Each individual is recorded along with their age, gender, race, offense, and sentence length, among other things.\n",
    "\n",
    "I also created one-hot encoded versions of this data set in order to run regressions on the data. Because of the size of the data, the regression data sets are only random subsets of the larger data set.\n",
    "\n",
    "Because there is so much to consider in what is found in the data set, I chose not to engineer more features as to avoid unneeded complexity.\n",
    "\n",
    "The sample sizes among different races that are found in the Connecticut Department of Justice data are not similar. The sample size for American Indians and Asians is much smaller than that of Whites, Hispanics, and Blacks, hence we may see some irregular outcomes in the analysis related to these racial groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RACE</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>AGE</th>\n",
       "      <th>OFFENSE</th>\n",
       "      <th>FACILITY</th>\n",
       "      <th>DETAINER</th>\n",
       "      <th>SENTENCE DAYS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3989571</th>\n",
       "      <td>BLACK</td>\n",
       "      <td>M</td>\n",
       "      <td>26</td>\n",
       "      <td>ROBBERY, FIRST DEGREE                 BF</td>\n",
       "      <td>CHESHIRE CI</td>\n",
       "      <td>NONE</td>\n",
       "      <td>2922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889007</th>\n",
       "      <td>HISPANIC</td>\n",
       "      <td>M</td>\n",
       "      <td>24</td>\n",
       "      <td>VIOLATION OF PROBATION OR COND DISCHG</td>\n",
       "      <td>OSBORN CI</td>\n",
       "      <td>NONE</td>\n",
       "      <td>913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5845086</th>\n",
       "      <td>BLACK</td>\n",
       "      <td>M</td>\n",
       "      <td>29</td>\n",
       "      <td>ASSAULT, FIRST DEGREE                 BF</td>\n",
       "      <td>WILLARD-CYBULSKI CI</td>\n",
       "      <td>NONE</td>\n",
       "      <td>5479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2630893</th>\n",
       "      <td>BLACK</td>\n",
       "      <td>M</td>\n",
       "      <td>55</td>\n",
       "      <td>FAILURE TO APPEAR, SECOND DEGREE      AM</td>\n",
       "      <td>ROBINSON CI</td>\n",
       "      <td>NONE</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1850991</th>\n",
       "      <td>WHITE</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>CONSPIRACY</td>\n",
       "      <td>CHESHIRE CI</td>\n",
       "      <td>NONE</td>\n",
       "      <td>5479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997278</th>\n",
       "      <td>HISPANIC</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>ROBBERY, FIRST DEGREE                 BF</td>\n",
       "      <td>GARNER</td>\n",
       "      <td>NONE</td>\n",
       "      <td>3653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56101</th>\n",
       "      <td>WHITE</td>\n",
       "      <td>M</td>\n",
       "      <td>27</td>\n",
       "      <td>ASSAULT, THIRD DEGREE                 AM</td>\n",
       "      <td>ROBINSON CI</td>\n",
       "      <td>NONE</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1568920</th>\n",
       "      <td>WHITE</td>\n",
       "      <td>M</td>\n",
       "      <td>24</td>\n",
       "      <td>ARSON, FIRST DEGREE                   AF</td>\n",
       "      <td>OSBORN CI</td>\n",
       "      <td>NONE</td>\n",
       "      <td>2557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269971</th>\n",
       "      <td>BLACK</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>ASSAULT, FIRST DEGREE                 BF</td>\n",
       "      <td>ROBINSON CI</td>\n",
       "      <td>NONE</td>\n",
       "      <td>2922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7093563</th>\n",
       "      <td>BLACK</td>\n",
       "      <td>M</td>\n",
       "      <td>24</td>\n",
       "      <td>CRIMINAL TRESPASS, FIRST DEGREE       AM</td>\n",
       "      <td>CORRIGAN CI</td>\n",
       "      <td>NONE</td>\n",
       "      <td>455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             RACE GENDER  AGE                                   OFFENSE  \\\n",
       "3989571     BLACK      M   26  ROBBERY, FIRST DEGREE                 BF   \n",
       "1889007  HISPANIC      M   24     VIOLATION OF PROBATION OR COND DISCHG   \n",
       "5845086     BLACK      M   29  ASSAULT, FIRST DEGREE                 BF   \n",
       "2630893     BLACK      M   55  FAILURE TO APPEAR, SECOND DEGREE      AM   \n",
       "1850991     WHITE      M   45                                CONSPIRACY   \n",
       "3997278  HISPANIC      M   25  ROBBERY, FIRST DEGREE                 BF   \n",
       "56101       WHITE      M   27  ASSAULT, THIRD DEGREE                 AM   \n",
       "1568920     WHITE      M   24  ARSON, FIRST DEGREE                   AF   \n",
       "1269971     BLACK      M   25  ASSAULT, FIRST DEGREE                 BF   \n",
       "7093563     BLACK      M   24  CRIMINAL TRESPASS, FIRST DEGREE       AM   \n",
       "\n",
       "                    FACILITY DETAINER  SENTENCE DAYS  \n",
       "3989571          CHESHIRE CI     NONE           2922  \n",
       "1889007            OSBORN CI     NONE            913  \n",
       "5845086  WILLARD-CYBULSKI CI     NONE           5479  \n",
       "2630893          ROBINSON CI     NONE            365  \n",
       "1850991          CHESHIRE CI     NONE           5479  \n",
       "3997278               GARNER     NONE           3653  \n",
       "56101            ROBINSON CI     NONE            365  \n",
       "1568920            OSBORN CI     NONE           2557  \n",
       "1269971          ROBINSON CI     NONE           2922  \n",
       "7093563          CORRIGAN CI     NONE            455  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['RACE','GENDER','AGE','OFFENSE','FACILITY','DETAINER','SENTENCE DAYS']\n",
    "features = ['GENDER','AGE','OFFENSE','FACILITY','DETAINER','SENTENCE DAYS']\n",
    "df = pd.read_csv('individuals.csv',usecols=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size for Blacks: 3287596\n",
      "Sample size for Whites: 2393949\n",
      "Sample size for Hispanic: 2039297\n",
      "Sample size for American Indian: 21133\n",
      "Sample size for Asian: 35660\n"
     ]
    }
   ],
   "source": [
    "races = {'BLACK':'Blacks','WHITE':'Whites',\n",
    "         'HISPANIC':'Hispanic','AMER IND':'American Indian',\n",
    "         'ASIAN':'Asian'\n",
    "        }\n",
    "for rac in races.keys():\n",
    "    mask = df.RACE == rac\n",
    "    print(f'Sample size for {races[rac]}: {len(df[mask])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Possible questions\n",
    "can we use ml techniques to correctly classify this data?\n",
    "which ones fail and why?\n",
    "can we create a predictive model for sentence lengths?\n",
    "should sentencing be offloaded to a ml algorithm?\n",
    "what does it mean to have an effective classfifier for this data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunksize = 100000\n",
    "# rdf = pd.read_csv('regression_df.csv', chunksize=chunksize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['RACE','GENDER','AGE','OFFENSE','FACILITY','DETAINER','SENTENCE DAYS']\n",
    "features = ['GENDER','AGE','OFFENSE','FACILITY','DETAINER','SENTENCE DAYS']\n",
    "df = pd.read_csv('individuals.csv',usecols=cols) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Techniques\n",
    "TSNE is having poor results and UMAP doesn't seem to capture any good groupings.\n",
    "### TALK ABOUT UMAP MORE\n",
    "I could block by crime and examine a few \"big\" crimes the try several different perplexities, however I do not think that clusting will be helpful in this case. Especially becasue I have not yet found a kernel that converts crimes to a spacial variable.\n",
    "\n",
    "there are other techniques that are not applicable to this data. For example, since this data set is not a time series models like ARMA and HMM are not applicable here.\n",
    "\n",
    "## Random Forest Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = df.sample(20000)\n",
    "samp.RACE = pd.factorize(samp['RACE'])[0] + 1\n",
    "samp.GENDER = pd.factorize(samp['GENDER'])[0] + 1\n",
    "samp.OFFENSE = pd.factorize(samp['OFFENSE'])[0] + 1\n",
    "samp.DETAINER = pd.factorize(samp['DETAINER'])[0] + 1\n",
    "samp.FACILITY = pd.factorize(samp['FACILITY'])[0] + 1\n",
    "samp_y = samp.RACE\n",
    "samp_X = samp[['GENDER','AGE','OFFENSE','FACILITY','DETAINER','SENTENCE DAYS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to train is 223.73655876318614 minutes\n",
      "oob score is 0.70645\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': np.arange(100,400,20),\n",
    "    'max_depth': np.arange(10,100,10),\n",
    "    'max_features': np.arange(1,6)\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(oob_score=True)\n",
    "\n",
    "s = time.time()\n",
    "clf = GridSearchCV(clf, param_grid, scoring=None, cv=5)\n",
    "clf = clf.fit(samp_X, samp_y)\n",
    "e = time.time()\n",
    "print(f'time to train is {(e-s)/60} minutes')\n",
    "\n",
    "clf = clf.best_estimator_\n",
    "clf = clf.fit(samp_X, samp_y)\n",
    "print(f'oob score is {clf.oob_score_}')\n",
    "\n",
    "with open('RandomForestClf.pickle', \"wb+\") as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ethan/.local/lib/python3.7/site-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.20.3 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.70645\n",
      "[0.01022266 0.26942225 0.2124008  0.17300606 0.0338177  0.30113052]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ethan/.local/lib/python3.7/site-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.20.3 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "with open('RandomForestClf.pickle',\"rb\") as f:\n",
    "    clf = pickle.load(f)\n",
    "print(clf.oob_score_)\n",
    "print(clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we can see that the most important features are sentence length, age, and offense. And the high OoB score is promising."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.420315"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samp = df.sample(200000)\n",
    "samp.RACE = pd.factorize(samp['RACE'])[0] + 1\n",
    "samp.GENDER = pd.factorize(samp['GENDER'])[0] + 1\n",
    "samp.OFFENSE = pd.factorize(samp['OFFENSE'])[0] + 1\n",
    "samp.DETAINER = pd.factorize(samp['DETAINER'])[0] + 1\n",
    "samp.FACILITY = pd.factorize(samp['FACILITY'])[0] + 1\n",
    "samp_y = samp.RACE\n",
    "samp_X = samp[['GENDER','AGE','OFFENSE','FACILITY','DETAINER','SENTENCE DAYS']]\n",
    "clf.score(samp_X, samp_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However the score is not great. Random chance would be .2, so it does do better than chance, though not much better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent Boosted Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = df.sample(10000)\n",
    "samp.RACE = pd.factorize(samp['RACE'])[0] + 1\n",
    "samp.GENDER = pd.factorize(samp['GENDER'])[0] + 1\n",
    "samp.OFFENSE = pd.factorize(samp['OFFENSE'])[0] + 1\n",
    "samp.DETAINER = pd.factorize(samp['DETAINER'])[0] + 1\n",
    "samp.FACILITY = pd.factorize(samp['FACILITY'])[0] + 1\n",
    "samp_y = samp.RACE\n",
    "samp_X = samp[['GENDER','AGE','OFFENSE','FACILITY','DETAINER','SENTENCE DAYS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'learning_rate': np.linspace(.01,1,10),\n",
    "    'subsample': np.linspace(.05,1,10),\n",
    "    'max_depth': np.arange(1,5)\n",
    "}\n",
    "\n",
    "clf = GradientBoostingClassifier(n_estimators=5000)\n",
    "\n",
    "s = time.time()\n",
    "# clf = GridSearchCV(clf, param_grid, cv=5)\n",
    "clf = clf.fit(samp_X, samp_y)\n",
    "e = time.time()\n",
    "\n",
    "# clf = clf.best_estimator_\n",
    "# clf = clf.fit(samp_X, samp_y)\n",
    "\n",
    "print(f'time is {(e-s)/60}')\n",
    "\n",
    "with open('GradientBoostedClf1.pickle', \"wb+\") as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.296365"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samp = df.sample(200000)\n",
    "samp.RACE = pd.factorize(samp['RACE'])[0] + 1\n",
    "samp.GENDER = pd.factorize(samp['GENDER'])[0] + 1\n",
    "samp.OFFENSE = pd.factorize(samp['OFFENSE'])[0] + 1\n",
    "samp.DETAINER = pd.factorize(samp['DETAINER'])[0] + 1\n",
    "samp.FACILITY = pd.factorize(samp['FACILITY'])[0] + 1\n",
    "samp_y = samp.RACE\n",
    "samp_X = samp[['GENDER','AGE','OFFENSE','FACILITY','DETAINER','SENTENCE DAYS']]\n",
    "clf.score(samp_X, samp_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02090027 0.24716962 0.25775903 0.10433119 0.03748648 0.33235341]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ethan/.local/lib/python3.7/site-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator DecisionTreeRegressor from version 0.20.3 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/ethan/.local/lib/python3.7/site-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator GradientBoostingClassifier from version 0.20.3 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "with open('GradientBoostedClf.pickle', \"rb\") as f:\n",
    "    clf = pickle.load(f)\n",
    "#     print(f'oob improvement {clf.oob_improvement_}')\n",
    "#     to_print = zip(clf.feature_importances_,features)\n",
    "    print(clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see the same feature importances as we did with the random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'friedman_mse',\n",
       " 'init': None,\n",
       " 'learning_rate': 0.34,\n",
       " 'loss': 'deviance',\n",
       " 'max_depth': 4,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 600,\n",
       " 'n_iter_no_change': None,\n",
       " 'presort': 'auto',\n",
       " 'random_state': None,\n",
       " 'subsample': 1.0,\n",
       " 'tol': 0.0001,\n",
       " 'validation_fraction': 0.1,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = df.sample(10000)\n",
    "samp.RACE = pd.factorize(samp['RACE'])[0] + 1\n",
    "samp.GENDER = pd.factorize(samp['GENDER'])[0] + 1\n",
    "samp.OFFENSE = pd.factorize(samp['OFFENSE'])[0] + 1\n",
    "samp.DETAINER = pd.factorize(samp['DETAINER'])[0] + 1\n",
    "samp.FACILITY = pd.factorize(samp['FACILITY'])[0] + 1\n",
    "samp_y = samp.RACE\n",
    "samp_X = samp[['GENDER','AGE','OFFENSE','FACILITY','DETAINER','SENTENCE DAYS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time was 1.7242353409528732 hours\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'learning_rate':np.linspace(.01,1,5),\n",
    "    'reg_alpha':np.linspace(.01,1,5),\n",
    "    'reg_lambda':np.linspace(.01,1,5),\n",
    "    'gamma':np.linspace(.01,1,5)\n",
    "}\n",
    "\n",
    "clf = xgboost.XGBClassifier(verbose=2)\n",
    "s = time.time()\n",
    "clf = GridSearchCV(clf, param_grid,cv=5)\n",
    "clf = clf.fit(samp_X, samp_y)\n",
    "\n",
    "with open('XBG_fitted_grid.pickle', 'wb+') as f:\n",
    "    pickle.dump(clf, f)\n",
    "\n",
    "clf = clf.best_estimator_\n",
    "clf = clf.fit(samp_X, samp_y)\n",
    "e = time.time()\n",
    "\n",
    "print(f'time was {(e-s)/(60*60)} hours')\n",
    "\n",
    "with open('XGBoostClf.pickle', 'wb+') as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = df.sample(200000)\n",
    "samp.RACE = pd.factorize(samp['RACE'])[0] + 1\n",
    "samp.GENDER = pd.factorize(samp['GENDER'])[0] + 1\n",
    "samp.OFFENSE = pd.factorize(samp['OFFENSE'])[0] + 1\n",
    "samp.DETAINER = pd.factorize(samp['DETAINER'])[0] + 1\n",
    "samp.FACILITY = pd.factorize(samp['FACILITY'])[0] + 1\n",
    "samp_y = samp.RACE\n",
    "samp_X = samp[['GENDER','AGE','OFFENSE','FACILITY','DETAINER','SENTENCE DAYS']]\n",
    "# clf.score(samp_X,samp_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41374\n",
      "[0.2596316  0.132617   0.1624777  0.12035192 0.18768501 0.13723671]\n"
     ]
    }
   ],
   "source": [
    "with open('XGBoostClf.pickle', \"rb\") as f:\n",
    "    clf = pickle.load(f)\n",
    "#     print(f'oob improvement {clf.oob_improvement_}')\n",
    "#     to_print = zip(clf.feature_importances_,features)\n",
    "    print(clf.score(samp_X,samp_y))\n",
    "    print(clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This score is very promiseing since the score is about double chance. There actually is a lot of correct classification going on here. \n",
    "\n",
    "Interestingly however, it seems that the feature importances are very different for this model. Gender is the most important feature nad every other feature is about equally important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KD Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "\n",
    "# Analysis\n",
    "\n",
    "\n",
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "[[1]](https://www.aclu.org/other/statement-concern-about-predictive-policing-aclu-and-16-civil-rights-privacy-racial-justice) Statement Of Concern About Predictive Policing By Aclu and 16 Civil Rights Privacy, Racial Justice, and Technology Organizations\n",
    "https://www.aclu.org/other/statement-concern-about-predictive-policing-aclu-and-16-civil-rights-privacy-racial-justice\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
