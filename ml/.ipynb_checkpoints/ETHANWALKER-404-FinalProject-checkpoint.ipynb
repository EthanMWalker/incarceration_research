{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.linalg as la\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import umap\n",
    "import pickle\n",
    "import time\n",
    "import xgboost\n",
    "\n",
    "from sklearn import linear_model, model_selection, metrics\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as GDA\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import GridSearchCV,train_test_split,cross_val_score\n",
    "from sklearn.metrics import roc_auc_score as RAS\n",
    "from sklearn.metrics import roc_curve as ROC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "source": [
    "```bash\n",
    "jupyter nbconvert --output-dir='./tex' --to latex \"ETHANWALKER-404-FinalProject.ipynb\" --TagRemovePreprocessor.remove_input_tags='{\"hide_input\"}'; pdflatex tex/ETHANWALKER-404-FinalProject\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "Machine Learning is becomeing a more prevelant tool in the world of criminal justice. Often it is used to predict who will commit a crime or where crimes may occur. Seldom is it used to regulate the criminal justice system, however. In this project I examine prison inmate data and determine what machine learning techniques are effective at detecting the racial bias that has been shown to exist in this data. In this report I find ---------\n",
    "\n",
    "# Problem Statement and Motivation\n",
    "Last semester I took a look a data set containing the information of more than 7.5 million individuals that have been processed by the criminal justice system. I found that racial minorities were more likely to receive extreme sentences, agreeing with existing research around bias in the criminal justice system. In this project I will be exploring the data from a machine learning perspective. My goal is to determine if this data can be classified in such a way that is predictive of race. The idea is that perhaps racial bias can be detected in various systems by seeing how effective different machine learning techniques are at classifying an inmate's by race given their data.\n",
    "\n",
    "This is an unconventional way to approach criminal justice data with machine learning. Often we see machine learning being used to attempt to determine who might be a criminal or where crimal activity may occur using social media data and other public information, which may include data the government owns, but which is not available to te public. These approaches often ignore or discount the ways that these techniques may disproportionately affect people of color and the poor. Many organizations have made official statements reguarding the use of machine learning in this way, often called predicitive policing. The ACLU for example released a statement listing civil rights related concerns about predicitive policing which was signed by several civil rights origanizations includeing the NAACP [[1]](https://www.aclu.org/other/statement-concern-about-predictive-policing-aclu-and-16-civil-rights-privacy-racial-justice).\n",
    "\n",
    "My objective is to go against the predictive policing paradigm and use machine learning to benefit these negatively affected classes of people by using machine learning as a diagnostic tool. If it can be shown that certain machine learning techniques are effective at classifying inmates by race given incarceration related information, then we can inform policies that will attempt to correct for these systemic racial biases. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "## Source and Credibility\n",
    "The data that I will be using in this analysis is from one source. It is a [database](https://catalog.data.gov/dataset/sentenced-inmates-in-correctional-facilities) hosted on [Data.gov](https://www.data.gov) and maintained by the State of Connecticut Department of Corrections. This source is highly credible because it is a primary source for the data. This organization is an official government agency which collects, maintains, and reports on this data.\n",
    "\n",
    "## Gathering and Cleaning\n",
    "All the data which I am using in this report are freely available to the public. Collection and cleaning was relatively simple as the source data was well maintained. The file that I obtained from the Connecticut Department of Corrections is a very well maintained database. The largest issue I had with this file was mild inconsistency with the way in which certain data was encoded (ex. race was encoded as both `WHITE` and `WHITE\\t`). The file is\n",
    "```\n",
    "individuals.csv.\n",
    "\n",
    "```\n",
    "## About the Data\n",
    "This data set contains individual information for 7.77 million people that have been processed by the justice system and recorded by the Connecticut Department of Corrections. Each individual is recorded along with their age, gender, race, offense, and sentence length, among other things.\n",
    "\n",
    "Because there is so much to consider in what is found in the data set, I chose not to feature engineer as to avoid unneeded complexity.\n",
    "\n",
    "The sample sizes among different races that are found in the Connecticut Department of Justice data are not similar. The sample size for American Indians and Asians is much smaller than that of Whites, Hispanics, and Blacks, hence we may see some irregular outcomes in the analysis related to these racial groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "# chunksize = 100000\n",
    "# rdf = pd.read_csv('regression_df.csv', chunksize=chunksize)\n",
    "cols = ['RACE','GENDER','AGE','OFFENSE','FACILITY','DETAINER','SENTENCE DAYS']\n",
    "features = ['GENDER','AGE','OFFENSE','FACILITY','DETAINER','SENTENCE DAYS']\n",
    "df = pd.read_csv('individuals.csv',usecols=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size for Blacks: 3287596\n",
      "Sample size for Whites: 2393949\n",
      "Sample size for Hispanic: 2039297\n",
      "Sample size for American Indian: 21133\n",
      "Sample size for Asian: 35660\n"
     ]
    }
   ],
   "source": [
    "races = {'BLACK':'Blacks','WHITE':'Whites',\n",
    "         'HISPANIC':'Hispanic','AMER IND':'American Indian',\n",
    "         'ASIAN':'Asian'\n",
    "        }\n",
    "for rac in races.keys():\n",
    "    mask = df.RACE == rac\n",
    "    print(f'Sample size for {races[rac]}: {len(df[mask])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods\n",
    "Before I begin discussing the methods that I did use, I will talk about some of the methods that I did not use. There are manay techniques that are not applicable to this data. For example, since this data set is not a time series models like ARMA and HMM are not applicable here. \n",
    "\n",
    "## Dimension Reduction\n",
    "A method that I attempted to use, but found little success with were dimension reduction tools like PCA, T-SNE, and UMAP. This dimension reduction would have been helpful, especially because once one-hot encoded this data becomes extremely high dimensional. However PCA, T-SNE, and UMAP all failed to create meaningful clusters, so I abandoned the the pursuit of clustering early on. Perhaps some kernel methods would have been helpful in this endeavor, however I could not find a kernel that could create a metric on crimes and I dp not feel qualified to write one myself.\n",
    "\n",
    "Below I have images of my attempt to use PCA, T-SNE, and UMAP to cluster the data. It is apperent that it simply is not effective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "samp = df.sample(20000)\n",
    "samp.RACE = pd.factorize(samp['RACE'])[0] + 1\n",
    "samp.GENDER = pd.factorize(samp['GENDER'])[0] + 1\n",
    "samp.OFFENSE = pd.factorize(samp['OFFENSE'])[0] + 1\n",
    "samp.DETAINER = pd.factorize(samp['DETAINER'])[0] + 1\n",
    "samp.FACILITY = pd.factorize(samp['FACILITY'])[0] + 1\n",
    "samp_y = samp.RACE\n",
    "samp_X = samp[['GENDER','AGE','OFFENSE','FACILITY','DETAINER','SENTENCE DAYS']]\n",
    "\n",
    "p = 30\n",
    "\n",
    "X = TSNE(perplexity=p).fit_transform(samp_X)\n",
    "\n",
    "mask0 = samp_y == 0\n",
    "mask1 = samp_y == 1\n",
    "mask2 = samp_y == 2\n",
    "mask3 = samp_y == 3\n",
    "mask4 = samp_y == 4\n",
    "plt.scatter(X[:,0][mask0],X[:,1][mask0],marker='.')\n",
    "plt.scatter(X[:,0][mask1],X[:,1][mask1],marker='.')\n",
    "plt.scatter(X[:,0][mask2],X[:,1][mask2],marker='.')\n",
    "plt.scatter(X[:,0][mask3],X[:,1][mask3],marker='.')\n",
    "plt.scatter(X[:,0][mask4],X[:,1][mask4],marker='.')\n",
    "plt.title('T-SNE Dimension Reduction, Factorized Features')\n",
    "plt.savefig('./images/TSNE1.pdf',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "samp = df.sample(20000).copy()\n",
    "samp.RACE = pd.factorize(samp['RACE'])[0] + 1\n",
    "gender = pd.get_dummies(samp.GENDER).drop('F',axis=1)\n",
    "offense = pd.get_dummies(samp.OFFENSE).drop('POSSESSION OF NARCOTICS',axis=1)\n",
    "det = pd.get_dummies(samp.DETAINER).drop('IMMIGRATION',axis=1)\n",
    "fac = pd.get_dummies(samp.FACILITY).drop('MACDOUGALL',axis=1)\n",
    "samp_y = samp.RACE\n",
    "samp_X = pd.concat(\n",
    "    [\n",
    "        samp[['AGE','SENTENCE DAYS']],\n",
    "        gender, offense, det, fac\n",
    "    ], axis = 1\n",
    ") \n",
    "\n",
    "p = 30\n",
    "\n",
    "\n",
    "reducer = umap.UMAP()\n",
    "X = reducer.fit_transform(samp_X)\n",
    "\n",
    "mask0 = samp_y == 0\n",
    "mask1 = samp_y == 1\n",
    "mask2 = samp_y == 2\n",
    "mask3 = samp_y == 3\n",
    "mask4 = samp_y == 4\n",
    "plt.scatter(X[:,0][mask0],X[:,1][mask0],marker='.')\n",
    "plt.scatter(X[:,0][mask1],X[:,1][mask1],marker='.')\n",
    "plt.scatter(X[:,0][mask2],X[:,1][mask2],marker='.')\n",
    "plt.scatter(X[:,0][mask3],X[:,1][mask3],marker='.')\n",
    "plt.scatter(X[:,0][mask4],X[:,1][mask4],marker='.')\n",
    "plt.title('T-SNE Dimension Reduction, One-Hot Encoded Features')\n",
    "plt.savefig('./images/TSNE2.pdf',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "samp = df.sample(20000)\n",
    "samp.RACE = pd.factorize(samp['RACE'])[0] + 1\n",
    "samp.GENDER = pd.factorize(samp['GENDER'])[0] + 1\n",
    "samp.OFFENSE = pd.factorize(samp['OFFENSE'])[0] + 1\n",
    "samp.DETAINER = pd.factorize(samp['DETAINER'])[0] + 1\n",
    "samp.FACILITY = pd.factorize(samp['FACILITY'])[0] + 1\n",
    "samp_y = samp.RACE\n",
    "samp_X = samp[['GENDER','AGE','OFFENSE','FACILITY','DETAINER','SENTENCE DAYS']]\n",
    "\n",
    "reducer = umap.UMAP()\n",
    "X = reducer.fit_transform(samp_X)\n",
    "\n",
    "\n",
    "mask0 = samp_y == 0\n",
    "mask1 = samp_y == 1\n",
    "mask2 = samp_y == 2\n",
    "mask3 = samp_y == 3\n",
    "mask4 = samp_y == 4\n",
    "plt.scatter(X[:,0][mask0],X[:,1][mask0],marker='.')\n",
    "plt.scatter(X[:,0][mask1],X[:,1][mask1],marker='.')\n",
    "plt.scatter(X[:,0][mask2],X[:,1][mask2],marker='.')\n",
    "plt.scatter(X[:,0][mask3],X[:,1][mask3],marker='.')\n",
    "plt.scatter(X[:,0][mask4],X[:,1][mask4],marker='.')\n",
    "plt.title('UMAP Dimension Reduction, Factorized Features')\n",
    "plt.savefig('./images/UMAP1.pdf',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "samp = df.sample(20000).copy()\n",
    "samp.RACE = pd.factorize(samp['RACE'])[0] + 1\n",
    "gender = pd.get_dummies(samp.GENDER).drop('F',axis=1)\n",
    "offense = pd.get_dummies(samp.OFFENSE).drop('POSSESSION OF NARCOTICS',axis=1)\n",
    "det = pd.get_dummies(samp.DETAINER).drop('IMMIGRATION',axis=1)\n",
    "fac = pd.get_dummies(samp.FACILITY).drop('MACDOUGALL',axis=1)\n",
    "samp_y = samp.RACE\n",
    "samp_X = pd.concat(\n",
    "    [\n",
    "        samp[['AGE','SENTENCE DAYS']],\n",
    "        gender, offense, det, fac\n",
    "    ], axis = 1\n",
    ") \n",
    "\n",
    "reducer = umap.UMAP()\n",
    "X = reducer.fit_transform(samp_X)\n",
    "\n",
    "\n",
    "mask0 = samp_y == 0\n",
    "mask1 = samp_y == 1\n",
    "mask2 = samp_y == 2\n",
    "mask3 = samp_y == 3\n",
    "mask4 = samp_y == 4\n",
    "plt.scatter(X[:,0][mask0],X[:,1][mask0],marker='.')\n",
    "plt.scatter(X[:,0][mask1],X[:,1][mask1],marker='.')\n",
    "plt.scatter(X[:,0][mask2],X[:,1][mask2],marker='.')\n",
    "plt.scatter(X[:,0][mask3],X[:,1][mask3],marker='.')\n",
    "plt.scatter(X[:,0][mask4],X[:,1][mask4],marker='.')\n",
    "plt.title('UMAP Dimension Reduction, One-Hot Encoded Features')\n",
    "plt.savefig('./images/UMAP2.pdf',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "samp = df.sample(20000).copy()\n",
    "samp.RACE = pd.factorize(samp['RACE'])[0] + 1\n",
    "gender = pd.get_dummies(samp.GENDER).drop('F',axis=1)\n",
    "offense = pd.get_dummies(samp.OFFENSE).drop('POSSESSION OF NARCOTICS',axis=1)\n",
    "det = pd.get_dummies(samp.DETAINER).drop('IMMIGRATION',axis=1)\n",
    "fac = pd.get_dummies(samp.FACILITY).drop('MACDOUGALL',axis=1)\n",
    "samp_y = samp.RACE\n",
    "samp_X = pd.concat(\n",
    "    [\n",
    "        samp[['AGE','SENTENCE DAYS']],\n",
    "        gender, offense, det, fac\n",
    "    ], axis = 1\n",
    ") \n",
    "pca = PCA(2)\n",
    "X = pca.fit_transform(samp_X)\n",
    "\n",
    "\n",
    "mask0 = samp_y == 0\n",
    "mask1 = samp_y == 1\n",
    "mask2 = samp_y == 2\n",
    "mask3 = samp_y == 3\n",
    "mask4 = samp_y == 4\n",
    "plt.scatter(X[:,0][mask0],X[:,1][mask0],marker='.')\n",
    "plt.scatter(X[:,0][mask1],X[:,1][mask1],marker='.')\n",
    "plt.scatter(X[:,0][mask2],X[:,1][mask2],marker='.')\n",
    "plt.scatter(X[:,0][mask3],X[:,1][mask3],marker='.')\n",
    "plt.scatter(X[:,0][mask4],X[:,1][mask4],marker='.')\n",
    "plt.title('PCA Dimension Reduction, One-Hot Encoded Features')\n",
    "plt.savefig('./images/PCA.pdf',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is only a small sample of things that I tried to do to get useful clusterings given the dimension reduction, though it is representitive of the results I found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Methods\n",
    "Ensamble methods seemed imediately like the methods that I should be using in this project. I did not intially expect to successfully classify this data, however as I learned about how ensamble classifiers worked I became more confident that I would get decent results.\n",
    "\n",
    "The primary reason that I though I would not get good results has to do with how I identified racial bias in the data. In my previous project I determined that there was racial bias in the criminal justice system based on the kurtosis of the distribution of sentence lenghts, when you block inmates by race. Interpreted this means that minorities are much more likely to receive an extreme sentence length than a white person is. This condition is very subtle and I did not think that it would be easily detectable by machine learning methods. However, ensamble methods only need each member to do slightly better than random, so there was hope that I could get good results with these methods.\n",
    "\n",
    "The methods that I attempted were the following: random forrest classifier, gradient descent boosted classifier, XGBoost, and LightGBM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true,
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "samp = df.sample(20000)\n",
    "samp.RACE = pd.factorize(samp['RACE'])[0] + 1\n",
    "samp.GENDER = pd.factorize(samp['GENDER'])[0] + 1\n",
    "samp.OFFENSE = pd.factorize(samp['OFFENSE'])[0] + 1\n",
    "samp.DETAINER = pd.factorize(samp['DETAINER'])[0] + 1\n",
    "samp.FACILITY = pd.factorize(samp['FACILITY'])[0] + 1\n",
    "samp_y = samp.RACE\n",
    "samp_X = samp[['GENDER','AGE','OFFENSE','FACILITY','DETAINER','SENTENCE DAYS']]\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': np.arange(100,5100,500),\n",
    "    'max_depth': np.arange(5,100,10)\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(oob_score=True)\n",
    "\n",
    "s = time.time()\n",
    "clf = GridSearchCV(clf, param_grid, scoring=None, cv=5)\n",
    "clf = clf.fit(samp_X, samp_y)\n",
    "e = time.time()\n",
    "print(f'time to train is {(e-s)/60} minutes')\n",
    "\n",
    "with open('./pickles/RandomForest_fitted_grid.pickle', \"wb+\") as f:\n",
    "    pickle.dump(clf, f)\n",
    "\n",
    "\n",
    "clf = clf.best_estimator_\n",
    "clf = clf.fit(samp_X, samp_y)\n",
    "# print(f'oob score is {clf.oob_score_}')\n",
    "\n",
    "with open('./pickles/RandomForestClf.pickle', \"wb+\") as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "samp = df.sample(20000)\n",
    "samp.RACE = pd.factorize(samp['RACE'])[0] + 1\n",
    "samp.GENDER = pd.factorize(samp['GENDER'])[0] + 1\n",
    "samp.OFFENSE = pd.factorize(samp['OFFENSE'])[0] + 1\n",
    "samp.DETAINER = pd.factorize(samp['DETAINER'])[0] + 1\n",
    "samp.FACILITY = pd.factorize(samp['FACILITY'])[0] + 1\n",
    "samp_y = samp.RACE\n",
    "samp_X = samp[['GENDER','AGE','OFFENSE','FACILITY','DETAINER','SENTENCE DAYS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'learning_rate': np.linspace(.01,1,10),\n",
    "    'subsample': np.linspace(.05,1,10)\n",
    "}\n",
    "\n",
    "clf = GradientBoostingClassifier(n_estimators=5000, max_depth=85)\n",
    "\n",
    "s = time.time()\n",
    "clf = GridSearchCV(clf, param_grid, cv=5)\n",
    "clf = clf.fit(samp_X, samp_y)\n",
    "e = time.time()\n",
    "\n",
    "with open('./pickles/GB_fitted_grid1.pickle', \"wb+\") as f:\n",
    "    pickle.dump(clf, f)\n",
    "\n",
    "clf = clf.best_estimator_\n",
    "clf = clf.fit(samp_X, samp_y)\n",
    "\n",
    "print(f'time is {(e-s)/60}')\n",
    "\n",
    "with open('./pickles/GradientBoostedClf1.pickle', \"wb+\") as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "samp = df.sample(20000)\n",
    "samp.RACE = pd.factorize(samp['RACE'])[0] + 1\n",
    "samp.GENDER = pd.factorize(samp['GENDER'])[0] + 1\n",
    "samp.OFFENSE = pd.factorize(samp['OFFENSE'])[0] + 1\n",
    "samp.DETAINER = pd.factorize(samp['DETAINER'])[0] + 1\n",
    "samp.FACILITY = pd.factorize(samp['FACILITY'])[0] + 1\n",
    "samp_y = samp.RACE\n",
    "samp_X = samp[['GENDER','AGE','OFFENSE','FACILITY','DETAINER','SENTENCE DAYS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'reg_alpha':np.linspace(.01,1,10),\n",
    "    'reg_lambda':np.linspace(.01,1,10),\n",
    "    'gamma':np.linspace(.01,1,10)\n",
    "}\n",
    "\n",
    "clf = xgboost.XGBClassifier(learning_rate=1)\n",
    "s = time.time()\n",
    "clf = GridSearchCV(clf, param_grid,cv=5)\n",
    "clf = clf.fit(samp_X, samp_y)\n",
    "\n",
    "with open('./pickles/XBG_fitted_grid.pickle', 'wb+') as f:\n",
    "    pickle.dump(clf, f)\n",
    "\n",
    "clf = clf.best_estimator_\n",
    "clf = clf.fit(samp_X, samp_y)\n",
    "e = time.time()\n",
    "\n",
    "# print(f'time was {(e-s)/(60*60)} hours')\n",
    "\n",
    "with open('./pickles/XGBoostClf.pickle', 'wb+') as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM\n",
    "\n",
    "LightGBM is an attempt to improve upon the efficiency, both temporally and spatially, of different grandient boosted decision tree (GBDT) algorithms such as XGBoost. This algoritm was developed by a team at Microsoft and it uses two novel techniques to imporove GBDT algorithms. The baseline comparison used was against XGBoost, since the team found this method to be the best performer of the commonly used GBDT algorithms.\n",
    "\n",
    "By analyzing GBDT algorithms the team found that the most expensive parts of the process is learning the decision trees and the most expensive part of learning the decision trees is finding the best split points. They decided to use a histogram based approach for efficiency. This process is dominated by the histogram building which has a complexity of $O(\\#data \\times \\#feature)$. Now the goal is to reduce the feature number or the number of data points.\n",
    "\n",
    "#### Gradient-based One-Side Sampling\n",
    "This is the first novel technique proposed by the Microsoft team. It is a sampling method that is meant to reduce the number of data instances while maintaing accuracy. The main idea here is that data points with small gradient are usually ignored, since the model is already will trained on those data instances. However, the changes that occur by ignoring the data will small gradient may reduce the accuracy of the model once it is learned. Therefore GOSS examines all of the high gradient data and a random sample of the small gradient data. This method can maximize the amount of relevent data used in the training of the model without handicapping the accuracy completely.\n",
    "\n",
    "#### Exclusive Feature Bundling\n",
    "This is the second novel technique and its goal is to reduce the number of features. This technique relies on the fact that high dimensional data tend to be sparse, and therefore there are likely large bundles of features that are mutually exclusive are nearly mutually exclusive. These features can be bundled into a single feature and their histograms can be combined. This reduces the complexity of building histograms from $O(\\#data \\times \\#feature)$ to $O(\\#data \\times \\#bundle)$ and if $\\#bundle << \\#feature$ then the total complexity is greatly reduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "samp = df.sample(20000)\n",
    "samp.RACE = pd.factorize(samp['RACE'])[0] + 1\n",
    "samp.GENDER = pd.factorize(samp['GENDER'])[0] + 1\n",
    "samp.OFFENSE = pd.factorize(samp['OFFENSE'])[0] + 1\n",
    "samp.DETAINER = pd.factorize(samp['DETAINER'])[0] + 1\n",
    "samp.FACILITY = pd.factorize(samp['FACILITY'])[0] + 1\n",
    "samp_y = samp.RACE\n",
    "samp_X = samp[['GENDER','AGE','OFFENSE','FACILITY','DETAINER','SENTENCE DAYS']]\n",
    "with open('./pickles/LGBM_fitted_grid.pickle',\"rb\") as f:\n",
    "    clf = pickle.load(f)\n",
    "    \n",
    "    clf = clf.best_estimator_\n",
    "    clf = clf.fit(samp_X,samp_y)\n",
    "\n",
    "with open('./pickles/LGBMClf.pickle', 'wb+') as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "## Random Forest Classifier\n",
    "The random forest classifier was an easy place to begin in my attempt to find a successful classifier. It is a simple method and would likely give me a good lower bound on the success that I would have.\n",
    "\n",
    "In using the random forest classifier I did a gridsearch for the best parameters. The parameters I decided to seach over are the number of trees in the classifier and the maximum depth of the trees in the classifier. I chose this because having more trees in the classifier will improve the accuracy, however if the depth of each of the trees in unbounded then overfitting of the individual trees may become an issue.\n",
    "\n",
    "In my gridsearch I found the best parameters to be the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "with open('./pickles/RandomForestClf.pickle',\"rb\") as f:\n",
    "    clf = pickle.load(f)\n",
    "    print('Max Depth = {}'.format(clf.get_params()['max_depth']))\n",
    "    print('Number of Estimators = {}.'.format(clf.get_params()['n_estimators']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My results with the random forest classifier were rather disappointing, especially given the amount of time it took to train which was 5.32 hours on the following parameter grid \n",
    "\n",
    "```python\n",
    "param_grid = {\n",
    "    'n_estimators': np.arange(100,5100,500),\n",
    "    'max_depth': np.arange(5,100,10)\n",
    "}\n",
    "```\n",
    "\n",
    "which amounts to a 100 parameter grid.\n",
    "\n",
    "The out-of-box score was rather promising at .70 however the method scored barely better than chance. Here is a scoring of the model I ran:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ethan/anaconda3/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.20.3 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/ethan/anaconda3/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.20.3 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on a test size of 500000 is 0.286044\n"
     ]
    }
   ],
   "source": [
    "size = 500000\n",
    "samp = df.sample(size)\n",
    "samp.RACE = pd.factorize(samp['RACE'])[0] + 1\n",
    "samp.GENDER = pd.factorize(samp['GENDER'])[0] + 1\n",
    "samp.OFFENSE = pd.factorize(samp['OFFENSE'])[0] + 1\n",
    "samp.DETAINER = pd.factorize(samp['DETAINER'])[0] + 1\n",
    "samp.FACILITY = pd.factorize(samp['FACILITY'])[0] + 1\n",
    "samp_y = samp.RACE\n",
    "samp_X = samp[['GENDER','AGE','OFFENSE','FACILITY','DETAINER','SENTENCE DAYS']]\n",
    "clf.score(samp_X,samp_y)\n",
    "\n",
    "with open('./pickles/RandomForestClf.pickle',\"rb\") as f:\n",
    "    clf = pickle.load(f)\n",
    "    score = clf.score(samp_X,samp_y)\n",
    "    print(f'score on a test size of {size} is {score}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scoring here is lackluster to say the least though it did give me hope for more complex methods to preform better.\n",
    "\n",
    "## Gradient Descent Boosted Classification\n",
    "This method is an obvious next step after a random forest. With the ability to alter the subsample rate and the learning rate, I expect to get better results with this model. I began by doing another grid search, but I used some of the results from the previous search on the random forest model to save time. Fitting the following grid\n",
    "\n",
    "\n",
    "```python\n",
    "param_grid = {\n",
    "    'learning_rate': np.linspace(.01,1,10),\n",
    "    'subsample': np.linspace(.05,1,10)\n",
    "}\n",
    "```\n",
    "\n",
    "I found the following parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "with open('./pickles/GradientBoostedClf1.pickle',\"rb\") as f:\n",
    "    clf = pickle.load(f)\n",
    "    print('Max Depth = {}'.format(clf.get_params()['max_depth']))\n",
    "    print('Number of Estimators = {}.'.format(clf.get_params()['n_estimators']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model scored slightly better than the random forest model, as expected giving the following score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "size = 5000000\n",
    "samp = df.sample(size)\n",
    "samp.RACE = pd.factorize(samp['RACE'])[0] + 1\n",
    "samp.GENDER = pd.factorize(samp['GENDER'])[0] + 1\n",
    "samp.OFFENSE = pd.factorize(samp['OFFENSE'])[0] + 1\n",
    "samp.DETAINER = pd.factorize(samp['DETAINER'])[0] + 1\n",
    "samp.FACILITY = pd.factorize(samp['FACILITY'])[0] + 1\n",
    "samp_y = samp.RACE\n",
    "samp_X = samp[['GENDER','AGE','OFFENSE','FACILITY','DETAINER','SENTENCE DAYS']]\n",
    "\n",
    "with open('./pickles/GradientBoostedClf1.pickle',\"rb\") as f:\n",
    "    clf = pickle.load(f)\n",
    "    score = clf.score(samp_X,samp_y)\n",
    "    print(f'score on a test size of {size} is {score}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "XGBoost was the best ensemble classifier of which I was aware when I began this project, so it was the obvious conclusion to my exploration of ensemble classifiers.\n",
    "\n",
    "The grid I used was the following\n",
    "\n",
    "```python\n",
    "param_grid = {\n",
    "    'reg_alpha':np.linspace(.01,1,10),\n",
    "    'reg_lambda':np.linspace(.01,1,10),\n",
    "    'gamma':np.linspace(.01,1,10)\n",
    "}\n",
    "```\n",
    "\n",
    "and I found the following parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "with open('./pickles/XGBoostClf.pickle', \"rb\") as f:\n",
    "    clf = pickle.load(f)\n",
    "    params = clf.get_params()\n",
    "    print('L1 Regularization = {}'.format(clf.get_params()['reg_alpha']))\n",
    "    print('L2 Regularization = {}.'.format(clf.get_params()['reg_lambda']))\n",
    "    print('Minimum loss reduction = {}.'.format(clf.get_params()['gamma']))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost scores very well compared to the other methods that I used, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "size = 5000000\n",
    "samp = df.sample(size)\n",
    "samp.RACE = pd.factorize(samp['RACE'])[0] + 1\n",
    "samp.GENDER = pd.factorize(samp['GENDER'])[0] + 1\n",
    "samp.OFFENSE = pd.factorize(samp['OFFENSE'])[0] + 1\n",
    "samp.DETAINER = pd.factorize(samp['DETAINER'])[0] + 1\n",
    "samp.FACILITY = pd.factorize(samp['FACILITY'])[0] + 1\n",
    "samp_y = samp.RACE\n",
    "samp_X = samp[['GENDER','AGE','OFFENSE','FACILITY','DETAINER','SENTENCE DAYS']]\n",
    "\n",
    "with open('./pickles/XGBoostClf1.pickle',\"rb\") as f:\n",
    "    clf = pickle.load(f)\n",
    "    score = clf.score(samp_X,samp_y)\n",
    "    print(f'score on a test size of {size} is {score}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM\n",
    "Because I was very new to LightGBM when I began, I did a grid search on the following grid \n",
    "\n",
    "```python\n",
    "param_grid = {\n",
    "    'boosting_type': ['gbdt','dart','goss'],\n",
    "    'learning_rate': np.linspace(.01,1,10),\n",
    "    'n_estimators': np.arange(100,1100,100),\n",
    "    'max_depth': np.arange(0,10)\n",
    "}\n",
    "```\n",
    "\n",
    "and I found the following best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "with open('./pickles/LGBMClf.pickle',\"rb\") as f:\n",
    "    clf = pickle.load(f)\n",
    "    print('Boosting Type = {}'.format(clf.get_params()['boosting_type']))\n",
    "    print('Learning Rate = {}'.format(clf.get_params()['learning_rate']))\n",
    "    print('Number of Estimators = {}'.format(clf.get_params()['n_estimators']))    \n",
    "    print('Maximum Depth = {}.'.format(clf.get_params()['max_depth']))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that a max depth <= 0 indicates that the depth is unbounded. Searching over this grid of size 4000 is something that I would have never even tried for XGBoost or any other GBDT method, though it still did take slightly more than 20 hours to fit\n",
    "\n",
    "After this I did a grid search on the following grid\n",
    "\n",
    "```python\n",
    "param_grid = {\n",
    "    'reg_alpha': np.linspace(.1,1,10),\n",
    "    'reg_lambda': np.linspace(.1,1,10)\n",
    "}\n",
    "```\n",
    "\n",
    "and found --------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "with open('./pickles/LGBMClf1.pickle',\"rb\") as f:\n",
    "    clf = pickle.load(f)\n",
    "    print('L1 Regularization = {}'.format(clf.get_params()['reg_alpha']))\n",
    "    print('L2 Regularization = {}'.format(clf.get_params()['reg_lambda']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LightGBM scored comparible to XGBoost, as expected with what was reported in the paper introducing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "size = 5000000\n",
    "samp = df.sample(size)\n",
    "samp.RACE = pd.factorize(samp['RACE'])[0] + 1\n",
    "samp.GENDER = pd.factorize(samp['GENDER'])[0] + 1\n",
    "samp.OFFENSE = pd.factorize(samp['OFFENSE'])[0] + 1\n",
    "samp.DETAINER = pd.factorize(samp['DETAINER'])[0] + 1\n",
    "samp.FACILITY = pd.factorize(samp['FACILITY'])[0] + 1\n",
    "samp_y = samp.RACE\n",
    "samp_X = samp[['GENDER','AGE','OFFENSE','FACILITY','DETAINER','SENTENCE DAYS']]\n",
    "\n",
    "with open('./pickles/LGBMClf1.pickle',\"rb\") as f:\n",
    "    clf = pickle.load(f)\n",
    "    score = clf.score(samp_X,samp_y)\n",
    "    print(f'score on a test size of {size} is {score}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importances \n",
    "The only thing left to report about the results of my research is to examine the different assigned feature importances.\n",
    "They are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "with open('./pickles/RandomForestClf.pickle',\"rb\") as f:\n",
    "    clf = pickle.load(f)\n",
    "    imp = clf.feature_importances_\n",
    "    print('Random Forest:')\n",
    "    for i in range(len(imp)):\n",
    "        print(f'\\t{features[i]} = {imp[i]}')\n",
    "\n",
    "with open('./pickles/GradientBoostedClf1.pickle',\"rb\") as f:\n",
    "    clf = pickle.load(f)\n",
    "    imp = clf.feature_importances_\n",
    "    print('Gradient Boosted Classifier:')\n",
    "    for i in range(len(imp)):\n",
    "        print(f'\\t{features[i]} = {imp[i]}')\n",
    "        \n",
    "with open('./pickles/XGBoostClf1.pickle',\"rb\") as f:\n",
    "    clf = pickle.load(f)\n",
    "    imp = clf.feature_importances_\n",
    "    print('XGBoost:')\n",
    "    for i in range(len(imp)):\n",
    "        print(f'\\t{features[i]} = {imp[i]}')\n",
    "        \n",
    "with open('./pickles/LGBMClf1.pickle',\"rb\") as f:\n",
    "    clf = pickle.load(f)\n",
    "    imp = clf.feature_importances_\n",
    "    print('LightGBM:')\n",
    "    for i in range(len(imp)):\n",
    "        print(f'\\t{features[i]} = {imp[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Analysis\n",
    "\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\n",
    "# References\n",
    "[[1]](https://www.aclu.org/other/statement-concern-about-predictive-policing-aclu-and-16-civil-rights-privacy-racial-justice) Statement Of Concern About Predictive Policing By Aclu and 16 Civil Rights Privacy, Racial Justice, and Technology Organizations\n",
    "https://www.aclu.org/other/statement-concern-about-predictive-policing-aclu-and-16-civil-rights-privacy-racial-justice\n",
    "\n",
    "\n",
    "[[2]](http://papers.nips.cc/paper/6907-lightgbm-a-highly-efficient-gradient-boosting-decision-tree.pdf) Ke, G., Meng, Q., Finley, T., Wang, T., Chen, W., Ma, W., … Liu, T.-Y. (2017). LightGBM: A Highly Efficient Gradient Boosting Decision Tree. Advances in Neural Information Processing Systems 30 (NIPS 2017). Retrieved from http://papers.nips.cc/paper/6907-lightgbm-a-highly-efficient-gradient-boosting-decision-tree.pdf"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
